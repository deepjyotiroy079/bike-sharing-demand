{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "round-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"bike-sharing-demand\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "joint-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = spark.read.csv(\"./data/train.csv\", header=True, inferSchema=True)\n",
    "testDF = spark.read.csv(\"./data/test.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "differential-influence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datetime: string (nullable = true)\n",
      " |-- season: integer (nullable = true)\n",
      " |-- holiday: integer (nullable = true)\n",
      " |-- workingday: integer (nullable = true)\n",
      " |-- weather: integer (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- atemp: double (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- casual: integer (nullable = true)\n",
      " |-- registered: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "occupied-stuff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10886"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "strategic-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = trainDF.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "precious-sunrise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10886"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fiscal-geography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+-------+----------+-------+-----+------+--------+---------+------+----------+-----+\n",
      "|           datetime|season|holiday|workingday|weather| temp| atemp|humidity|windspeed|casual|registered|count|\n",
      "+-------------------+------+-------+----------+-------+-----+------+--------+---------+------+----------+-----+\n",
      "|2011-01-01 00:00:00|     1|      0|         0|      1| 9.84|14.395|      81|      0.0|     3|        13|   16|\n",
      "|2011-01-01 01:00:00|     1|      0|         0|      1| 9.02|13.635|      80|      0.0|     8|        32|   40|\n",
      "|2011-01-01 02:00:00|     1|      0|         0|      1| 9.02|13.635|      80|      0.0|     5|        27|   32|\n",
      "|2011-01-01 03:00:00|     1|      0|         0|      1| 9.84|14.395|      75|      0.0|     3|        10|   13|\n",
      "|2011-01-01 04:00:00|     1|      0|         0|      1| 9.84|14.395|      75|      0.0|     0|         1|    1|\n",
      "|2011-01-01 05:00:00|     1|      0|         0|      2| 9.84| 12.88|      75|   6.0032|     0|         1|    1|\n",
      "|2011-01-01 06:00:00|     1|      0|         0|      1| 9.02|13.635|      80|      0.0|     2|         0|    2|\n",
      "|2011-01-01 07:00:00|     1|      0|         0|      1|  8.2| 12.88|      86|      0.0|     1|         2|    3|\n",
      "|2011-01-01 08:00:00|     1|      0|         0|      1| 9.84|14.395|      75|      0.0|     1|         7|    8|\n",
      "|2011-01-01 09:00:00|     1|      0|         0|      1|13.12|17.425|      76|      0.0|     8|         6|   14|\n",
      "|2011-01-01 10:00:00|     1|      0|         0|      1|15.58|19.695|      76|  16.9979|    12|        24|   36|\n",
      "|2011-01-01 11:00:00|     1|      0|         0|      1|14.76|16.665|      81|  19.0012|    26|        30|   56|\n",
      "|2011-01-01 12:00:00|     1|      0|         0|      1|17.22| 21.21|      77|  19.0012|    29|        55|   84|\n",
      "|2011-01-01 13:00:00|     1|      0|         0|      2|18.86|22.725|      72|  19.9995|    47|        47|   94|\n",
      "|2011-01-01 14:00:00|     1|      0|         0|      2|18.86|22.725|      72|  19.0012|    35|        71|  106|\n",
      "|2011-01-01 15:00:00|     1|      0|         0|      2|18.04| 21.97|      77|  19.9995|    40|        70|  110|\n",
      "|2011-01-01 16:00:00|     1|      0|         0|      2|17.22| 21.21|      82|  19.9995|    41|        52|   93|\n",
      "|2011-01-01 17:00:00|     1|      0|         0|      2|18.04| 21.97|      82|  19.0012|    15|        52|   67|\n",
      "|2011-01-01 18:00:00|     1|      0|         0|      3|17.22| 21.21|      88|  16.9979|     9|        26|   35|\n",
      "|2011-01-01 19:00:00|     1|      0|         0|      3|17.22| 21.21|      88|  16.9979|     6|        31|   37|\n",
      "+-------------------+------+-------+----------+-------+-----+------+--------+---------+------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "standard-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, lit\n",
    "trainDF = trainDF.withColumn('season_1', when(trainDF['season']==1, lit(1)).otherwise(lit(0))) \\\n",
    "                .withColumn('season_2', when(trainDF['season']==2, lit(1)).otherwise(lit(0))) \\\n",
    "                .withColumn('season_3', when(trainDF['season']==3, lit(1)).otherwise(lit(0))) \\\n",
    "                .withColumn('season_4', when(trainDF['season']==4, lit(1)).otherwise(lit(0))).drop(trainDF['season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "destroyed-handle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datetime',\n",
       " 'holiday',\n",
       " 'workingday',\n",
       " 'weather',\n",
       " 'temp',\n",
       " 'atemp',\n",
       " 'humidity',\n",
       " 'windspeed',\n",
       " 'casual',\n",
       " 'registered',\n",
       " 'count',\n",
       " 'season_1',\n",
       " 'season_2',\n",
       " 'season_3',\n",
       " 'season_4']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wireless-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = trainDF.withColumn('weather_1', when(trainDF['weather']==1, lit(1)).otherwise(lit(0))) \\\n",
    "                .withColumn('weather_2', when(trainDF['weather']==2, lit(1)).otherwise(lit(0))) \\\n",
    "                .withColumn('weather_3', when(trainDF['weather']==3, lit(1)).otherwise(lit(0))) \\\n",
    "                .withColumn('weather_4', when(trainDF['weather']==4, lit(1)).otherwise(lit(0))).drop(trainDF['weather'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "naval-orchestra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datetime',\n",
       " 'holiday',\n",
       " 'workingday',\n",
       " 'temp',\n",
       " 'atemp',\n",
       " 'humidity',\n",
       " 'windspeed',\n",
       " 'casual',\n",
       " 'registered',\n",
       " 'count',\n",
       " 'season_1',\n",
       " 'season_2',\n",
       " 'season_3',\n",
       " 'season_4',\n",
       " 'weather_1',\n",
       " 'weather_2',\n",
       " 'weather_3',\n",
       " 'weather_4']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mechanical-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "trainDF = trainDF.withColumn('year', split(split(trainDF['datetime'], ' ')[0], '-')[0].cast('int'))\n",
    "trainDF = trainDF.withColumn('month', split(split(trainDF['datetime'], ' ')[0], '-')[1].cast('int'))\n",
    "trainDF = trainDF.withColumn('day', split(split(trainDF['datetime'], ' ')[0], '-')[2].cast('int'))\n",
    "trainDF = trainDF.withColumn('hour', split(split(trainDF['datetime'], ' ')[1], ':')[0].cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "isolated-annual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+\n",
      "|year|month|day|hour|\n",
      "+----+-----+---+----+\n",
      "|2011|    1|  1|   0|\n",
      "|2011|    1|  1|   1|\n",
      "|2011|    1|  1|   2|\n",
      "|2011|    1|  1|   3|\n",
      "|2011|    1|  1|   4|\n",
      "|2011|    1|  1|   5|\n",
      "|2011|    1|  1|   6|\n",
      "|2011|    1|  1|   7|\n",
      "|2011|    1|  1|   8|\n",
      "|2011|    1|  1|   9|\n",
      "|2011|    1|  1|  10|\n",
      "|2011|    1|  1|  11|\n",
      "|2011|    1|  1|  12|\n",
      "|2011|    1|  1|  13|\n",
      "|2011|    1|  1|  14|\n",
      "|2011|    1|  1|  15|\n",
      "|2011|    1|  1|  16|\n",
      "|2011|    1|  1|  17|\n",
      "|2011|    1|  1|  18|\n",
      "|2011|    1|  1|  19|\n",
      "+----+-----+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select('year', 'month', 'day', 'hour').show()\n",
    "trainDF = trainDF.drop('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "protecting-theology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|month|sum(count)|\n",
      "+-----+----------+\n",
      "|   12|    160160|\n",
      "|    1|     79884|\n",
      "|    6|    220733|\n",
      "|    3|    133501|\n",
      "|    5|    200147|\n",
      "|    9|    212529|\n",
      "|    4|    167402|\n",
      "|    8|    213516|\n",
      "|    7|    214617|\n",
      "|   10|    207434|\n",
      "|   11|    176440|\n",
      "|    2|     99113|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.groupBy('month').sum('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reported-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gathering all the features into one array using VectorAssembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['holiday', \\\n",
    "                                         'workingday', \\\n",
    "                                         'temp', \\\n",
    "                                         'atemp', \\\n",
    "                                         'humidity', \\\n",
    "                                         'windspeed', \\\n",
    "                                         'casual', \\\n",
    "                                         'registered', \\\n",
    "                                         'season_1', \\\n",
    "                                         'season_2', \\\n",
    "                                         'season_3', \\\n",
    "                                         'season_4', \\\n",
    "                                         'weather_1', \\\n",
    "                                         'weather_2', \\\n",
    "                                         'weather_3', \\\n",
    "                                         'weather_4', \\\n",
    "                                         'year', \\\n",
    "                                         'month', \\\n",
    "                                         'day', \\\n",
    "                                         'hour'], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "flush-trust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----+------+--------+---------+------+----------+-----+--------+--------+--------+--------+---------+---------+---------+---------+----+-----+---+----+--------------------+\n",
      "|holiday|workingday| temp| atemp|humidity|windspeed|casual|registered|count|season_1|season_2|season_3|season_4|weather_1|weather_2|weather_3|weather_4|year|month|day|hour|            features|\n",
      "+-------+----------+-----+------+--------+---------+------+----------+-----+--------+--------+--------+--------+---------+---------+---------+---------+----+-----+---+----+--------------------+\n",
      "|      0|         0| 9.84|14.395|      81|      0.0|     3|        13|   16|       1|       0|       0|       0|        1|        0|        0|        0|2011|    1|  1|   0|(20,[2,3,4,6,7,8,...|\n",
      "|      0|         0| 9.02|13.635|      80|      0.0|     8|        32|   40|       1|       0|       0|       0|        1|        0|        0|        0|2011|    1|  1|   1|(20,[2,3,4,6,7,8,...|\n",
      "|      0|         0| 9.02|13.635|      80|      0.0|     5|        27|   32|       1|       0|       0|       0|        1|        0|        0|        0|2011|    1|  1|   2|(20,[2,3,4,6,7,8,...|\n",
      "|      0|         0| 9.84|14.395|      75|      0.0|     3|        10|   13|       1|       0|       0|       0|        1|        0|        0|        0|2011|    1|  1|   3|(20,[2,3,4,6,7,8,...|\n",
      "|      0|         0| 9.84|14.395|      75|      0.0|     0|         1|    1|       1|       0|       0|       0|        1|        0|        0|        0|2011|    1|  1|   4|(20,[2,3,4,7,8,12...|\n",
      "|      0|         0| 9.84| 12.88|      75|   6.0032|     0|         1|    1|       1|       0|       0|       0|        0|        1|        0|        0|2011|    1|  1|   5|(20,[2,3,4,5,7,8,...|\n",
      "|      0|         0| 9.02|13.635|      80|      0.0|     2|         0|    2|       1|       0|       0|       0|        1|        0|        0|        0|2011|    1|  1|   6|(20,[2,3,4,6,8,12...|\n",
      "|      0|         0|  8.2| 12.88|      86|      0.0|     1|         2|    3|       1|       0|       0|       0|        1|        0|        0|        0|2011|    1|  1|   7|(20,[2,3,4,6,7,8,...|\n",
      "|      0|         0| 9.84|14.395|      75|      0.0|     1|         7|    8|       1|       0|       0|       0|        1|        0|        0|        0|2011|    1|  1|   8|(20,[2,3,4,6,7,8,...|\n",
      "|      0|         0|13.12|17.425|      76|      0.0|     8|         6|   14|       1|       0|       0|       0|        1|        0|        0|        0|2011|    1|  1|   9|(20,[2,3,4,6,7,8,...|\n",
      "|      0|         0|15.58|19.695|      76|  16.9979|    12|        24|   36|       1|       0|       0|       0|        1|        0|        0|        0|2011|    1|  1|  10|(20,[2,3,4,5,6,7,...|\n",
      "|      0|         0|14.76|16.665|      81|  19.0012|    26|        30|   56|       1|       0|       0|       0|        1|        0|        0|        0|2011|    1|  1|  11|(20,[2,3,4,5,6,7,...|\n",
      "|      0|         0|17.22| 21.21|      77|  19.0012|    29|        55|   84|       1|       0|       0|       0|        1|        0|        0|        0|2011|    1|  1|  12|(20,[2,3,4,5,6,7,...|\n",
      "|      0|         0|18.86|22.725|      72|  19.9995|    47|        47|   94|       1|       0|       0|       0|        0|        1|        0|        0|2011|    1|  1|  13|(20,[2,3,4,5,6,7,...|\n",
      "|      0|         0|18.86|22.725|      72|  19.0012|    35|        71|  106|       1|       0|       0|       0|        0|        1|        0|        0|2011|    1|  1|  14|(20,[2,3,4,5,6,7,...|\n",
      "|      0|         0|18.04| 21.97|      77|  19.9995|    40|        70|  110|       1|       0|       0|       0|        0|        1|        0|        0|2011|    1|  1|  15|(20,[2,3,4,5,6,7,...|\n",
      "|      0|         0|17.22| 21.21|      82|  19.9995|    41|        52|   93|       1|       0|       0|       0|        0|        1|        0|        0|2011|    1|  1|  16|(20,[2,3,4,5,6,7,...|\n",
      "|      0|         0|18.04| 21.97|      82|  19.0012|    15|        52|   67|       1|       0|       0|       0|        0|        1|        0|        0|2011|    1|  1|  17|(20,[2,3,4,5,6,7,...|\n",
      "|      0|         0|17.22| 21.21|      88|  16.9979|     9|        26|   35|       1|       0|       0|       0|        0|        0|        1|        0|2011|    1|  1|  18|(20,[2,3,4,5,6,7,...|\n",
      "|      0|         0|17.22| 21.21|      88|  16.9979|     6|        31|   37|       1|       0|       0|       0|        0|        0|        1|        0|2011|    1|  1|  19|(20,[2,3,4,5,6,7,...|\n",
      "+-------+----------+-----+------+--------+---------+------+----------+-----+--------+--------+--------+--------+---------+---------+---------+---------+----+-----+---+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = assembler.transform(trainDF)\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compressed-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = output.select('features', 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "transparent-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|count|\n",
      "+--------------------+-----+\n",
      "|(20,[2,3,4,6,7,8,...|   16|\n",
      "|(20,[2,3,4,6,7,8,...|   40|\n",
      "|(20,[2,3,4,6,7,8,...|   32|\n",
      "|(20,[2,3,4,6,7,8,...|   13|\n",
      "|(20,[2,3,4,7,8,12...|    1|\n",
      "|(20,[2,3,4,5,7,8,...|    1|\n",
      "|(20,[2,3,4,6,8,12...|    2|\n",
      "|(20,[2,3,4,6,7,8,...|    3|\n",
      "|(20,[2,3,4,6,7,8,...|    8|\n",
      "|(20,[2,3,4,6,7,8,...|   14|\n",
      "|(20,[2,3,4,5,6,7,...|   36|\n",
      "|(20,[2,3,4,5,6,7,...|   56|\n",
      "|(20,[2,3,4,5,6,7,...|   84|\n",
      "|(20,[2,3,4,5,6,7,...|   94|\n",
      "|(20,[2,3,4,5,6,7,...|  106|\n",
      "|(20,[2,3,4,5,6,7,...|  110|\n",
      "|(20,[2,3,4,5,6,7,...|   93|\n",
      "|(20,[2,3,4,5,6,7,...|   67|\n",
      "|(20,[2,3,4,5,6,7,...|   35|\n",
      "|(20,[2,3,4,5,6,7,...|   37|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "royal-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "train_data, test_data = final_df.randomSplit([0.80, 0.20])\n",
    "regressor = LinearRegression(featuresCol='features', labelCol='count')\n",
    "regressor = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "opposed-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0, -0.0, 0.0, -0.0, -0.0, -0.0, 1.0, 1.0, 0.0002, 0.0001, -0.0001, -0.0002, -0.0, 0.0, 0.0, 0.0001, -0.0, 0.0, -0.0, -0.0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "correct-roulette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006838714531440304"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "needed-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "massive-valentine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+\n",
      "|            features|count|        prediction|\n",
      "+--------------------+-----+------------------+\n",
      "|(20,[0,2,3,4,5,6,...|  159|158.99998931870277|\n",
      "|(20,[0,2,3,4,5,6,...|   97| 97.00009236053812|\n",
      "|(20,[0,2,3,4,5,6,...|   51| 50.99997458118856|\n",
      "|(20,[0,2,3,4,5,7,...|   13|13.000037975123519|\n",
      "|(20,[0,2,3,4,6,7,...|   68| 68.00001546121321|\n",
      "|(20,[0,2,3,4,6,7,...|    4| 4.000077397148832|\n",
      "|(20,[0,2,3,4,6,7,...|   19|18.999993386642714|\n",
      "|(20,[0,2,3,4,6,7,...|  408| 407.9999176762049|\n",
      "|(20,[0,2,3,4,6,7,...|  104|104.00007347954352|\n",
      "|(20,[0,2,3,4,6,7,...|   21| 20.99997845013404|\n",
      "|(20,[0,2,3,4,6,7,...|   34| 33.99999093738806|\n",
      "|(20,[0,2,3,4,6,7,...|  365|364.99998513124837|\n",
      "|(20,[1,2,3,4,5,6,...|   14|14.000009320582507|\n",
      "|(20,[1,2,3,4,5,6,...|    7| 6.999948807338305|\n",
      "|(20,[1,2,3,4,5,6,...|   25| 24.99994971844662|\n",
      "|(20,[1,2,3,4,5,6,...|   23| 23.00001765689744|\n",
      "|(20,[1,2,3,4,5,6,...|   23|23.000007876221044|\n",
      "|(20,[1,2,3,4,5,6,...|   17|17.000028042703494|\n",
      "|(20,[1,2,3,4,5,6,...|   11|11.000037114460907|\n",
      "|(20,[1,2,3,4,5,6,...|   57| 57.00005977355077|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "willing-undergraduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8017385166379496e-05"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Root Mean Square Error and Mean Absolute Error\n",
    "pred_results.meanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "placed-concept",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1049854215815446e-09"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-calcium",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
